---
title: "Reproducible Analysis of Zurich Leerkündigungen"
subtitle: "Open Government Data Analysis"
author: "Automated Analysis"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    theme: cosmo
    highlight: tango
    code_folding: hide
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6,
  dpi = 300
)

# Load required libraries
library(tidyverse)
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(scales)
library(forcats)

# Source all analysis scripts
source("../scripts/utils.R")
source("../scripts/01_load.R")
source("../scripts/02_explore.R")
source("../scripts/03_analyze.R")
source("../scripts/04_visualize.R")
```

# Executive Summary

This analysis examines Leerkündigungen (eviction notices due to building refurbishment) in Zurich using official Open Government Data. Key findings include:Temporal patterns,  age group differences** **Surprising patterns** **Statistical validation*

---

# 1. Data Loading and Validation

## 1.1 Dataset Source

Daten stammen vom OGD daten satz *** Hier Was Schreiben ***

**Official URL**: `https://data.stadt-zuerich.ch/dataset/bau_umbau_leerkuendigung_wohnortsgebiete_ag_personen_od5052/download/BAU505OD5052.csv`

```{r load-data}
# Load dataset from official URL
df_raw <- load_and_validate(DATASET_URL)
```

## 1.2 Column names

The dataset uses German column names. Map them to English names:

```{r field-mapping}
# Display new names
mapping_table <- data.frame(
  `New name` = names(FIELD_MAPPINGS),
  `Original name` = unlist(FIELD_MAPPINGS)
)

kable(mapping_table, caption = "Name Mappings")

# Apply renaming
df <- map_fields(df_raw)
```

---

# 2. Methodology

## 2.1 Aggregation Measure

**Definition**: All totals, shares, and comparisons use the **affected persons count** (`AnzPersonWir` in the dataset). This is the number of individuals who received a Leerkündigung.

## 2.2 Within/Outside City Categories

We define a binary grouping of residence outcomes for a first analysis:

**Within Zurich City**:

- `r WITHIN_CITY_CATEGORIES[1]` (Same city quarter)
- `r WITHIN_CITY_CATEGORIES[2]` (Different city quarter)

**Outside Zurich City**: All other residence categories (excluding "Unknown" if analyzed separately)

```{r within-outside-mapping}
# Display residence categories and their classification
residence_classification <- df %>%
  select(new_residence, within_city) %>%
  distinct() %>%
  arrange(desc(within_city), new_residence) %>%
  mutate(Classification = ifelse(within_city, "Within City", "Outside City"))

kable(residence_classification %>% select(new_residence, Classification), 
      caption = "Residence Category Classification")
```

## 2.3 Unknown Category Handling

If an "Unknown" category exists in the data:

- It is **reported explicitly** (not silently removed)
- Its distribution across age groups is analyzed separately (Q5)
- It is **excluded** from the Within/Outside city binary analysis to avoid bias

---

# 3. Exploration

```{r exploration}
# Run exploration
exploration_results <- explore_dataset(df)
```

## 3.1 Summary Statistics
## Todo make a table 
- **Time Range**: `r exploration_results$time_range$earliest` to `r exploration_results$time_range$latest` (`r exploration_results$time_range$span` years)
- **Total Affected Persons**: `r format(exploration_results$total_count, big.mark = ",")`
- **Age Groups**: `r length(exploration_results$age_groups)` categories
- **Residence Categories**: `r length(exploration_results$residence_categories)` categories

## 3.2 Unknown Category

```{r unknown-check}
if (exploration_results$unknown_info$exists) {
  cat("**Unknown category is PRESENT**\n\n")
  cat("- Count:", format(exploration_results$unknown_info$count, big.mark = ","), "\n")
  cat("- Share:", round(exploration_results$unknown_info$share * 100, 1), "%\n")
} else {
  cat("**Unknown category is NOT PRESENT**\n")
}
```


---

# 4. Analysis

## 4.1 Change over time

**Question**: How does the total affected count change over time?

```{r q1-analysis}

time_results <- analyze_time_change(df)

# Display results
cat("**Peak Year(s)**: ", paste(time_results$peak_years, collapse = ", "), "\n")
cat("**Peak Count**: ", format(time_results$peak_count, big.mark = ","), " affected persons\n")
```

### Total Affected Persons Over Time

```{r q1-visualization, fig.cap="Total affected persons over time"}
plot_persons_per_time(time_results$temporal_summary)
```

---

## 4.2 Distribution of the residence outcomes

**Question**: Is the distribution of new residence outcomes stable over time, or does it shift?

```{r q2-analysis}
q2_results <- analyze_composition_shift(df)

```

```{r q2-visualization, fig.cap="Residence composition over time"}
plot_composition_shift(q2_results$composition_summary, q2_results$deviant_years)
```

# Todo adda test


---

## 4.3 Q3: Age Gradient

**Question**: Do age groups differ in the likelihood of remaining within Zurich city vs moving outside?

```{r q3-analysis}
## ToDo Zeige die Differenz im text, sortiere die anteile nach prio

# Filter out unknown for this analysis
df_known <-  filter_unknown(df) 

q3_results <- analyze_age_gradient(df_known)

cat("**Strongest Contrast**:\n\n")
cat("- **", q3_results$max_age_group, "**: ", round(q3_results$max_share * 100, 1), "% within city\n", sep = "")
cat("- **", q3_results$min_age_group, "**: ", round(q3_results$min_share * 100, 1), "% within city\n", sep = "")
cat("- **Difference**: ", round(q3_results$contrast * 100, 1), " percentage points\n\n", sep = "")
```

### Within-City Share by Age Group

```{r q3-visualization, fig.cap="Within-city share by age group"}
plot_age_gradient(q3_results$age_summary)
```

```{r q3-table}
q3_table <- q3_results$age_summary %>%
  mutate(
    `Within City Share` = paste0(round(within_city_share * 100, 1), "%"),
    `Total Count` = format(total_count, big.mark = ",")
  ) %>%
  select(`Age Group` = age_group, `Within City Share`, `Total Count`)

kable(q3_table, caption = "Within-City Share by Age Group", align = c("l", "r", "r"))
```

**Interpretation**: There is a clear age gradient in residence outcomes. `r q3_results$max_age_group` has the highest within-city share (`r round(q3_results$max_share * 100, 1)`%), while `r q3_results$min_age_group` has the lowest (`r round(q3_results$min_share * 100, 1)`%), representing a `r round(q3_results$contrast * 100, 1)` percentage point difference.

---

## 4.4 Q4: Same-Quarter Dependence

**Question**: If "same city quarter" exists, does its share vary by age group?

```{r q4-analysis}
# Todo zeige einfach die same share im selben quartier, allenfalls mache ienen test
q4_results <- analyze_same_quarter(df)

if (q4_results$applicable) {
  cat("**Same-quarter analysis is APPLICABLE**\n\n")
  cat("**Strongest Contrast**:\n\n")
  cat("- **", q4_results$max_age_group, "**: ", round(q4_results$max_share * 100, 1), "% same quarter\n", sep = "")
  cat("- **", q4_results$min_age_group, "**: ", round(q4_results$min_share * 100, 1), "% same quarter\n", sep = "")
  cat("- **Difference**: ", round(q4_results$contrast * 100, 1), " percentage points\n\n", sep = "")
} else {
  cat("**Same-quarter analysis is NOT APPLICABLE** (category not present in dataset)\n")
}
```

```{r q4-visualization, eval=q4_results$applicable, fig.cap="Same-quarter share by age group"}
if (q4_results$applicable) {
  plot_same_quarter(q4_results$same_quarter_summary)
}
```

```{r q4-table, eval=q4_results$applicable}
if (q4_results$applicable) {
  q4_table <- q4_results$same_quarter_summary %>%
    mutate(
      `Same Quarter Share` = paste0(round(same_quarter_share * 100, 1), "%"),
      `Same Quarter Count` = format(same_quarter_count, big.mark = ","),
      `Total Count` = format(total, big.mark = ",")
    ) %>%
    select(`Age Group` = age_group, `Same Quarter Share`, `Same Quarter Count`, `Total Count`)
  
  kable(q4_table, caption = "Same-Quarter Share by Age Group", align = c("l", "r", "r", "r"))
}
```

---

## 4.5 Q5: Number of "unknowns"

**Question**: If "Unknown" exists, does it concentrate in certain age groups?

```{r q5-analysis}
#Todo mach das im Text
q5_results <- analyze_unknown_concentration(df)

if (q5_results$applicable) {
  cat("**Unknown concentration analysis is APPLICABLE**\n\n")
  cat("**Strongest Contrast**:\n\n")
  cat("- **", q5_results$max_age_group, "**: ", round(q5_results$max_share * 100, 1), "% unknown\n", sep = "")
  cat("- **", q5_results$min_age_group, "**: ", round(q5_results$min_share * 100, 1), "% unknown\n", sep = "")
  cat("- **Difference**: ", round(q5_results$contrast * 100, 1), " percentage points\n\n", sep = "")
  
  cat("**Plausible Non-Causal Reasons**:\n\n")
  cat("- Data collection practices may vary by age group\n")
  cat("- Certain age groups may be more mobile or harder to track\n")
  cat("- Administrative reporting differences across city quarters\n")
  cat("- Temporal changes in data quality over the study period\n")
} else {
  cat("**Unknown concentration analysis is NOT APPLICABLE** (Unknown category not present)\n")
}
```

```{r q5-visualization, eval=q5_results$applicable, fig.cap="Unknown residence share by age group"}
if (q5_results$applicable) {
  plot_unknown_concentration(q5_results$unknown_summary)
}
```

```{r q5-table, eval=q5_results$applicable}
if (q5_results$applicable) {
  q5_table <- q5_results$unknown_summary %>%
    mutate(
      `Unknown Share` = paste0(round(unknown_share * 100, 1), "%"),
      `Unknown Count` = format(unknown_count, big.mark = ","),
      `Total Count` = format(total, big.mark = ",")
    ) %>%
    select(`Age Group` = age_group, `Unknown Share`, `Unknown Count`, `Total Count`)
  
  kable(q5_table, caption = "Unknown Residence Share by Age Group", align = c("l", "r", "r", "r"))
}
```

---

# 5. Statistical Validation

## 5.1 Chi-Square Test

We test the association between age group and residence outcome (within vs outside city) using a chi-square test of independence. 

```{r statistical-test}
# ToDo: bring die Chi square sachen in eine tabelle als result, erklaere im text 
# Create contingency table (excluding unknown)
contingency_table <- df_known %>%
  mutate(outcome = ifelse(within_city, "Within City", "Outside City")) %>%
  group_by(age_group, outcome) %>%
  summarise(count = sum(count, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = outcome, values_from = count, values_fill = 0) %>%
  column_to_rownames("age_group") %>%
  as.matrix()

# Perform chi-square test
chi_result <- chisq.test(contingency_table)

# Calculate Cramér's V
n <- sum(contingency_table)
v <- cramers_v(chi_result, n)
v_interpretation <- interpret_cramers_v(v)

# Display results
cat("**Chi-Square Test Results:**\n\n")
cat("- **Test Statistic (χ²)**: ", round(chi_result$statistic, 2), "\n", sep = "")
cat("- **Degrees of Freedom**: ", chi_result$parameter, "\n", sep = "")
cat("- **P-value**: ", format.pval(chi_result$p.value, digits = 3), "\n\n", sep = "")

cat("**Effect Size (Cramér's V):**\n\n")
cat("- **V**: ", round(v, 3), "\n", sep = "")
cat("- **Interpretation**: ", v_interpretation, " effect\n\n", sep = "")
```

### Contingency Table

```{r contingency-table}
kable(contingency_table, caption = "Age Group × Residence Outcome Contingency Table")
```

## 5.2 Conservative Interpretation

**Findings**: The chi-square test `r if(chi_result$p.value < 0.05) "suggests a statistically significant association" else "does not show a statistically significant association"` between age group and residence outcome (p `r if(chi_result$p.value < 0.05) "<" else "="` `r format.pval(chi_result$p.value, digits = 3)`). The effect size (Cramér's V = `r round(v, 3)`) indicates a `r v_interpretation` effect.

**Limitations**:

- This is **aggregate-level data**, not individual-level
- The analysis is **observational**, not experimental
- We **cannot infer causation** from these associations
- The findings describe **patterns**, not mechanisms
- Other unmeasured factors may influence the observed associations

**Conclusion**: The data suggests systematic differences in residence outcomes across age groups, but these should be interpreted as descriptive patterns rather than causal relationships.

---

# 6. Verteilungen Zwischen Zielorten und Altersgruppen


## 6.2 Total variations-Distanzmatrix: Wie ähnlich sind die Jahre bezüglich Zielort-Verteilung?

Um zu prüfen, ob sich die Zielorte nach Leerkündigung über die Zeit nur in der Menge, aber auch in der **Struktur** (Komposition) verändern, berechne ich für jedes Jahr die Verteilung der Kategorien `new_residence` als **Anteile**.

Für jedes Jahr \(t\) ergibt sich ein Vektor \(p^{(t)} = (p_1^{(t)}, \dots, p_K^{(t)})\), wobei \(p_i^{(t)}\) der Anteil der Betroffenen ist, die im Zielort \(i\) landen (Summe über alle Zielorte = 1).

Als Distanzmass verwende ich die **Total-Variation-Distanz (TV)** zwischen zwei Verteilungen \(p\) und \(q\):

\[
TV(p, q) \;=\; \frac{1}{2}\sum_{i=1}^{K} |p_i - q_i|
\]

**Interpretation:**
- \(TV = 0\): die beiden Jahre haben **identische** Zielort-Verteilungen.
- Je grösser \(TV\), desto **stärker** unterscheiden sich die Kompositionen.
- \(TV\) liegt immer zwischen 0 und 1. Als Faustregel: ein \(TV\) von 0.10 bedeutet, dass man insgesamt etwa 10 Prozentpunkte „Masse“ zwischen Kategorien verschieben müsste, um die eine Verteilung in die andere zu überführen.

Die resultierende paarweise Distanzmatrix über alle Jahre visualisiere ich als Heatmap: dunklere Felder markieren Jahre, deren Zielort-Verteilungen sich deutlich unterscheiden; helle Felder markieren ähnliche Jahre.

```{r vergleich distance matrix jahre}

shares <- df %>%
  group_by(year, new_residence) %>%
  summarise(x = sum(count, na.rm = TRUE), .groups = "drop") %>%
  group_by(year) %>%
  mutate(p = x / sum(x)) %>%
  ungroup() %>%
  select(year, new_residence, p) %>%
  pivot_wider(names_from = new_residence, values_from = p, values_fill = 0) %>%
  arrange(year)

years <- shares$year
M <- as.matrix(dplyr::select(shares, -year))

# Total Variation (TV) = 0.5 * L1 (Manhattan) distance between share vectors
D <- as.matrix(dist(M, method = "manhattan")) * 0.5
dimnames(D) <- list(years, years)

p4b_data <- as.data.frame(as.table(D)) %>%
  rename(y1 = Var1, y2 = Var2, tv = Freq)

p4b <- ggplot(p4b_data, aes(y2, y1, fill = tv)) +
  geom_tile() +
  labs(title = "TV-Distanzmatrix der Jahre (0 = identisch)", x = "Jahr", y = "Jahr")

p4b

```

## 6.3 Standardisierte Residuen (Alter × Zielort): Wo liegt der Zusammenhang genau?

Ein globaler Zusammenhang zwischen Altersgruppen und Zielorten ist leicht festzustellen, aber für die Interpretation ist entscheidend: **Welche Kombinationen treiben den Effekt?**  
Dafür berechne ich für die Kontingenztafel `age_group × new_residence` sogenannte **standardisierte Residuen** (Pearson-Residuen).

Zuerst aggregiere ich die beobachteten Häufigkeiten \(O_{a,r}\) (Summe von `count`) pro Altersgruppe \(a\) und Zielort \(r\).  
Unter der Nullhypothese **Unabhängigkeit** (Alter und Zielort sind unabhängig) wäre die erwartete Häufigkeit:

\[
E_{a,r} \;=\; \frac{(\text{Zeilensumme}_a)\,(\text{Spaltensumme}_r)}{\text{Gesamtsumme}}
\]

Das standardisierte Residuum ist dann:

\[
R_{a,r} \;=\; \frac{O_{a,r} - E_{a,r}}{\sqrt{E_{a,r}}}
\]

**Interpretation:**
- \(R_{a,r} > 0\): diese Kombination tritt **häufiger** auf als bei Unabhängigkeit erwartet (Überrepräsentation).
- \(R_{a,r} < 0\): diese Kombination tritt **seltener** auf als erwartet (Unterrepräsentation).
- Je grösser \(|R_{a,r}|\), desto stärker ist die lokale Abweichung (praktisch “Treiber-Zellen” des Zusammenhangs).

Ich visualisiere \(R_{a,r}\) als Heatmap, um die wichtigsten Abweichungen auf einen Blick zu erkennen.

```{r}
# Todo ordne die columns in der matrix nach distanz, alternativ clustering
# 1) Beobachtete Kontingenztafel O (age_group × new_residence)
ct_long <- df %>%
  group_by(age_group, new_residence) %>%
  summarise(O = sum(count, na.rm = TRUE), .groups = "drop")

ct <- ct_long %>%
  pivot_wider(names_from = new_residence, values_from = O, values_fill = 0)

age_labels <- ct$age_group
O <- as.matrix(select(ct, -age_group))

# 2) Erwartete Häufigkeiten E unter Unabhängigkeit
row_s <- rowSums(O)
col_s <- colSums(O)
grand <- sum(O)

E <- outer(row_s, col_s) / grand

# 3) Standardisierte Residuen R = (O - E) / sqrt(E)
R <- (O - E) / sqrt(E)

# 4) Für Plot ins Long-Format
Rdf <- as.data.frame(R)
Rdf$age_group <- age_labels

Rlong <- Rdf %>%
  pivot_longer(-age_group, names_to = "new_residence", values_to = "resid") %>%
  # Optional: Altersgruppen sortieren (falls AlterV20Sort vorhanden)
  left_join(df %>% distinct(age_group, AlterV20Sort), by = "age_group") %>%
  arrange(AlterV20Sort) %>%
  mutate(age_group = fct_inorder(age_group))

# 5) Plot
ggplot(Rlong, aes(new_residence, age_group, fill = resid)) +
  geom_tile() +
  labs(
    title = "Standardisierte Residuen: Alter × Zielort",
    subtitle = "R = (O − E) / sqrt(E); >0 über-, <0 unterrepräsentiert",
    x = "Zielort (new_residence)",
    y = "Altersgruppe",
    fill = "Residuum"
  ) +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```



# 6.4 log2(Relativrisiko) (Alter × Zielort): Über-/Unterrepräsentation verständlich quantifizieren

Die standardisierten Residuen (Figure 6) zeigen, **wo** Alter und Zielort voneinander abweichen. Für eine noch intuitivere Interpretation berechne ich zusätzlich ein **Relativrisiko** (RR) pro Kombination aus Altersgruppe und Zielort.

Dazu vergleiche ich:
- den Anteil eines Zielorts **innerhalb** einer Altersgruppe, und
- den Anteil desselben Zielorts **im Gesamtdatensatz**.

Für Altersgruppe \(a\) und Zielort \(r\) gilt:

\[
\text{row\_share}_{a,r} = \frac{O_{a,r}}{\sum_{r} O_{a,r}},
\quad
\text{overall\_share}_{r} = \frac{\sum_{a} O_{a,r}}{\sum_{a,r} O_{a,r}}
\]

\[
RR_{a,r} = \frac{\text{row\_share}_{a,r}}{\text{overall\_share}_{r}}
\]

Zur Darstellung verwende ich \(\log_2(RR)\), weil es symmetrisch interpretierbar ist:

- \(\log_2(RR)=0\): genau durchschnittlich (keine Über-/Unterrepräsentation)
- \(\log_2(RR)=+1\): etwa **2×** häufiger als im Durchschnitt
- \(\log_2(RR)=-1\): etwa **0.5×** so häufig wie im Durchschnitt

Ich visualisiere \(\log_2(RR)\) als Heatmap. Sehr kleine oder sehr grosse Werte können aus kleinen Zellen entstehen; daher ist es sinnvoll, die Farbskala moderat zu begrenzen (Clipping), damit die Grafik lesbar bleibt.

```{r fig-log2rr-heatmap, message=FALSE, warning=FALSE}

cap <- 2.5  # Farbskala begrenzen: +/- 2.5 ~ max ca. 5.7x hoch/runter

# 1) Beobachtete Häufigkeiten O (age_group × new_residence)
ct <- df %>%
  group_by(age_group, new_residence) %>%
  summarise(O = sum(count, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = new_residence, values_from = O, values_fill = 0)

ages <- ct$age_group
O <- as.matrix(select(ct, -age_group))

# 2) row_share: Anteil Zielort innerhalb Altersgruppe
row_share <- O / rowSums(O)

# 3) overall_share: Gesamtanteil Zielort
overall_share <- colSums(O) / sum(O)

# 4) Relativrisiko RR = row_share / overall_share
RR <- sweep(row_share, 2, overall_share, "/")

# 5) log2(RR) + Clipping für Lesbarkeit
log2RR <- log2(RR)
log2RR[is.infinite(log2RR)] <- NA
log2RR <- pmax(pmin(log2RR, cap), -cap)

# 6) Long-Format für Heatmap
log2RR_df <- as.data.frame(log2RR)
log2RR_df$age_group <- ages

long <- log2RR_df %>%
  pivot_longer(-age_group, names_to = "new_residence", values_to = "log2RR") %>%
  # Optional: Altersgruppen sortieren, falls AlterV20Sort existiert
  left_join(df %>% distinct(age_group, AlterV20Sort), by = "age_group") %>%
  arrange(AlterV20Sort) %>%
  mutate(age_group = fct_inorder(age_group))

# 7) Plot
ggplot(long, aes(new_residence, age_group, fill = log2RR)) +
  geom_tile() +
  labs(
    title = "log2(Relativrisiko): Über-/Unterrepräsentation Alter × Zielort",
    subtitle = "0 = durchschnittlich; +1 ≈ 2×; −1 ≈ 0.5× (Farbskala gekappt)",
    x = "Zielort (new_residence)",
    y = "Altersgruppe",
    fill = "log2(RR)"
  ) +
  theme_minimal(base_size = 12) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  scale_fill_distiller(palette = "inferno", direction = 1)
```


# 6.5

```{r}
```{r global-test-age-vs-destination, message=FALSE, warning=FALSE}
# Kontingenztafel: Altersgruppe × Zielort (gewichtete Counts)
tab <- xtabs(count ~ age_group + new_residence, data = df)

# Globaler χ²-Unabhängigkeitstest
chi <- chisq.test(tab)
chi

# Effektgrösse: Cramér's V
V <- sqrt(as.numeric(chi$statistic) / (sum(tab) * (min(nrow(tab)-1, ncol(tab)-1))))
V

```


# 7. Summary of Key Findings

1. **Temporal Dynamics (Q1)**: 

2. **Composition Shifts (Q2)**: `r if(length(q2_results$deviant_years) > 0) paste0("Year ", q2_results$most_deviant_year, " shows significant deviation from baseline composition") else "Composition remains relatively stable over time"`

3. **Age Gradient (Q3)**: Clear differences across age groups, with `r round(q3_results$contrast * 100, 1)` percentage point difference between `r q3_results$max_age_group` and `r q3_results$min_age_group`

4. **Statistical Validation**: Chi-square test `r if(chi_result$p.value < 0.05) "confirms" else "does not confirm"` systematic association (V = `r round(v, 3)`, `r v_interpretation` effect)


# Appendix A: Supplementary Figures

## S.Fig.A1

```{r supp-figure-a1}

# Aggregieren nach alter und wohnort
p13_data <- df %>%
  group_by(age_group, AlterV20Sort, new_residence) %>%
  summarise(x = sum(count, na.rm = TRUE), .groups = "drop") %>%
  group_by(age_group, AlterV20Sort) %>%
  mutate(share = x / sum(x)) %>%
  ungroup() %>%
  # Altersgruppen sauber sortieren
  arrange(AlterV20Sort) %>%
  mutate(age_group = fct_inorder(age_group))

# stacked plot 
p13 <- ggplot(p13_data, aes(x = age_group, y = share, fill = new_residence)) +
  geom_col(width = 0.85) +
  scale_y_continuous(labels = percent_format(accuracy = 1)) +
  labs(
    title = "Zielorte nach Leerkündigung: Zusammensetzung pro Altersgruppe",
    x = "Altersgruppe",
    y = "Anteil (100%)",
    fill = "Neuer Wohnort"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "right"
  )

p13
```

# Appendix B: Session Information

```{r session-info}
sessionInfo()
```

---

**Analysis completed**: `r Sys.time()`  
**Execution time**: `r round(as.numeric(Sys.time() - knitr::opts_chunk$get("start_time"), units = "secs"), 1)` seconds
